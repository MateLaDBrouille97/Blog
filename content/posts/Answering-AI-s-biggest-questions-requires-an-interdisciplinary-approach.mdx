---
title: "Answering AI’s biggest questions requires an interdisciplinary approach"
layout: "Article"
tags: 
  -AI 
  -IT
  -News
excerpt:
publishedAt:
---
<br/>
Tom Chavez, co-founder of superset, the chair of the Ethical Tech Project, and CEO of Boombox.io, highlights the urgent need for ethical considerations in the development of artificial intelligence (AI). He underscores the importance of addressing existential concerns about AI, especially in light of Elon Musk's new AI venture, xAI, which aims to understand the universe's true nature.
<br/>
Chavez argues that AI is not solely a computer science challenge but a human one that requires interdisciplinary collaboration. He suggests forming a "dream team" for companies to navigate the ethical aspects of AI:
<br/>
1. Chief AI and Data Ethicist: This role focuses on ethical data principles, data use, and citizens' rights regarding data consumed by AI, bridging communication between decision-makers and regulators.
<br/>
2. Chief Philosopher Architect: This position addresses long-term concerns, particularly the "Alignment Problem," defining safeguards and policies to align AI with human needs.
<br/>
3. Chief Neuroscientist: This expert delves into questions of sentience, human cognition models relevant to AI, and AI's potential contributions to understanding human cognition.
<br/>
Chavez emphasizes the need for technologists who can translate these concepts into functional software and product leaders who can envision "Human in the Loop" workflows to implement safeguards and ethical guidelines.
<br/>
He points out that even influential companies like OpenAI lack these leadership roles, leaving key questions unanswered. To build a responsible future with AI, companies must integrate diverse perspectives and prioritize ethical data use, ensuring AI innovation aligns with human well-being while maintaining ethical boundaries.
<br/>
<Button
  address="https://techcrunch.com/2023/09/15/answering-ais-biggest-questions-requires-an-interdisciplinary-approach/"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***EU to let ‘responsible’ AI startups train models on its supercomputers***
<br/>
The European Union (EU) has unveiled plans to provide access to its high-performance computing (HPC) supercomputers for startups to train AI models. However, there is a condition: these startups must adhere to the EU's AI governance principles. The EU had previously outlined voluntary AI rules while formal regulations were being developed, aiming to prepare companies for future AI rules. The EU is also working on the AI Act, a risk-based framework for AI regulation, which is expected to be adopted soon. It is also collaborating with international partners on an AI Code of Conduct to address global legislative gaps.
<br/>
The EU's plan includes offering access to its HPC supercomputers to "responsible" AI startups. The initiative was announced by EU President Ursula von der Leyen during her annual 'State of the Union' address. She expressed concerns about AI posing an existential risk and emphasized the need for responsible AI development.
<br/>
The EU currently has eight supercomputers, and it plans to open them up to AI startups to accelerate model training. This move aligns with the EU's broader efforts to guide AI innovation while ensuring ethical and safe AI practices. The EU also intends to convene the European AI Alliance Assembly in November to involve various stakeholders in AI governance.
<br/>
This initiative reflects the EU's commitment to leverage its HPC resources to encourage responsible AI innovation and highlights its dedication to addressing AI's societal impacts, from safety and ethics to governance.
<br/>
<Button
  address="https://techcrunch.com/2023/09/13/eu-supercomputers-for-ai/"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***OpenAI to open its first EU office as it readies for regulatory hurdles***
<br/>
OpenAI is establishing its first office within the European Union (EU) in Ireland, a strategic move as it anticipates regulatory challenges. This expansion follows the company's previous office openings in San Francisco and London. OpenAI's decision to set up in Ireland aligns with the trend of numerous U.S. tech companies choosing the country as a hub to engage with European lawmakers and customers, often benefiting from favorable tax rates.
<br/>
OpenAI is actively recruiting for nine positions in Dublin, including roles related to legal, privacy, policy, and engineering. These job openings reflect the company's commitment to addressing privacy concerns and data protection issues, which have arisen in Europe due to its AI products, notably ChatGPT.
<br/>
In the past, OpenAI faced scrutiny in Europe over data protection and transparency issues, with Italy and Spain temporarily blocking ChatGPT. Recently, the company was accused of data protection breaches in Poland, leading to a complaint filed with the local data protection authority.
<br/>
With the impending EU AI Act, which aims to regulate AI applications based on their perceived risks, OpenAI is proactively positioning itself in the EU. CEO Sam Altman has engaged with European regulators, emphasizing the importance of balanced AI regulation while advocating for international regulatory cooperation.
<br/>
While OpenAI's hiring efforts may seem modest compared to other tech giants, its presence in the EU signifies a commitment to navigate the evolving regulatory landscape and foster a positive relationship with European authorities. Given OpenAI's prominence in generative AI, it is likely to continue expanding its presence and lobbying efforts in Europe, where AI regulation is becoming a major focus for companies in the field.
<br/>
<Button
  address="https://techcrunch.com/2023/09/14/openai-dublin-eu-regulation/"
  text="Source"
/>
