---
title: "Growing public concern about the role of artificial intelligence in daily life"
layout: "Article"
tags: 
  -AI 
  -IT
  -Geopol
excerpt:
publishedAt:
---
<br/>
The UK government has announced that leading technology companies, including Meta, OpenAI, and Google DeepMind, have agreed to allow governments to vet their artificial intelligence (AI) products before they are released to the public. The move aims to slow down the development of AI systems that could potentially pose a grave risk to humanity. The announcement follows a two-day summit at Bletchley Park, where a diverse group, including world leaders and representatives from major technology companies, discussed the dangers of AI. Prime Minister Rishi Sunak stated that the agreements reached at the summit prove that the balance is shifting in favor of humanity. He also announced the establishment of an expert body, inspired by the Intergovernmental Panel on Climate Change, to monitor and publish reports on the state of AI science. The voluntary agreement for testing the safety of AI models is supported by 10 countries, including the US, UK, France, and Germany, as well as major tech companies like Google, Amazon, and Microsoft. The agreement is expected to be led by new AI safety institutes in the US and UK, with the UK positioning itself as a global hub for the initiative.
<br/>
<Button
  address="https://www.theguardian.com/technology/2023/nov/02/top-tech-firms-to-let-governments-vet-ai-tools-sunak-says-at-safety-summit"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***China, U.S., Japan, others agree to combat AI risks at U.K. summit***
<br/>
China has joined over 25 countries, including the US, UK, and Japan, at the AI Safety Summit in the UK to collaborate on combatting the risks associated with artificial intelligence (AI). The participating countries and the European Union released a joint statement, known as the Bletchley Declaration, highlighting the potential dangers of AI, such as cyberattacks. They pledged to work together to improve AI safety. The summit, attended by high-ranking officials and tech leaders including Elon Musk, aims to address cutting-edge AI issues, including the risks posed by AI use in cyberattacks, biological and chemical weapons development, and the loss of control over the technology. The participating countries urged AI companies to ensure safety and called for transparency and accountability in their plans. The summit also discussed establishing a framework, similar to the United Nations' Intergovernmental Panel on Climate Change, to share knowledge about the risks of AI and develop countermeasures. The UK, with its leading AI development centered on universities and research institutes, plans to establish a domestic AI safety institute, while the US announced its own institute. International bodies, such as the UN's advisory body and the Global Partnership on Artificial Intelligence, are also working towards addressing AI risk management. The challenge now is to delineate roles for each organization or potentially consolidate efforts to ensure safe use of AI and a conducive environment for AI development.
<br/>
<Button
  address="https://asia.nikkei.com/Business/Technology/China-U.S.-Japan-others-agree-to-combat"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Why AI Is Next Flashpoint in US-China Tech Rivalry***
<br/>
The US and China are engaged in a fierce competition in the field of artificial intelligence (AI), as both countries recognize its potential to boost productivity and influence geopolitics and military capabilities. The US is currently leading in generative AI systems, exemplified by the launch of OpenAI's ChatGPT chatbot. Silicon Valley is investing heavily in AI tools, with companies like Google and Microsoft competing to develop commercial applications. However, China is ahead in areas such as image recognition, but its generative AI tools still have room for improvement. Chinese technology giants like Baidu, Tencent, and Alibaba are making significant investments in AI, with promising results from chatbot trials. While the US leads in AI investment, China is gradually narrowing the gap, and it has been the leader in AI journal citations since 2010. The progress of AI in China is a concern for US officials due to its use in surveillance and military purposes. In response, the US has imposed restrictions on chip exports to China and tightened curbs on the sale of graphics chips for AI applications. The US government has also imposed limits on investments in Chinese semiconductor and AI firms to protect its technological supremacy. The limitations in China's AI development include the lack of access to US hardware, censorship, and flawed datasets. China has moved first to regulate its AI industry, requiring security reviews of AI services, while the US is still working towards enacting meaningful AI policies due to gridlock in Congress.
<br/>
<Button
  address="https://www.washingtonpost.com/business/2023/10/20/what-is-the-state-of-us-china-competition-in-ai/1ffa6780-6f53-11ee-b01a-f593caa04363_story.html"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***White House to unveil wide-ranging executive order on AI risks***
<br/>
President Joe Biden is set to sign an executive order on Monday that aims to increase safety and protect consumers, workers, and minority groups from the risks associated with artificial intelligence (AI). The executive order builds on previous voluntary commitments made by AI companies to make the technology safer. The new order requires developers of AI systems that pose risks to national security, the economy, public health, or safety to share the results of safety tests with the US government before they are released to the public. It also directs agencies to address related risks such as cybersecurity and sets standards for testing. The Commerce Department will develop guidance for content authentication and watermarking to label items generated by AI for clarity in government communications. The order also covers areas such as privacy, housing discrimination, and job displacement.
<br/>
The executive order is seen as a significant step in AI governance, with the White House calling it the "strongest set of actions" any government has taken to ensure AI security. The order comes as the Group of Seven industrial countries is expected to agree on a code of conduct for companies developing advanced AI systems. While the US has been criticized for lagging behind Europe in regulating AI, the senior administration official stressed that the executive order has the force of law and that legislative action from Congress is also necessary.
<br/>
The order highlights the risks of bias and civil rights violations associated with AI and calls for guidance to prevent AI algorithms from exacerbating discrimination. It also addresses the potential impact on workers, including job displacement, and requires a report on labor market impacts. Vice President Kamala Harris will attend an AI global summit in the UK this week, where China is also expected to be represented. British Prime Minister Rishi Sunak has emphasized the need for government action to tackle the risks posed by AI.
<br/>
<Button
  address="https://asia.nikkei.com/Business/Technology/White-House-to-unveil-wide-ranging-executive-order-on-AI-risks"
  text="Source"
/>
