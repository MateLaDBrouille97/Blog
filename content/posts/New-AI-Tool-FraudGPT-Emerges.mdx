---
title: "New AI Tool 'FraudGPT' Emerges, Tailored for Sophisticated Attacks"
layout: "Article"
tags: 
  -Definition
  -IT
  -News
  -Tech
  -Technologies
excerpt:
publishedAt:
---
<br/>
Cybercriminals are exploiting artificial intelligence (AI) technology for nefarious purposes with the emergence of a new tool called FraudGPT. Similar to WormGPT, this AI bot is being advertised on dark web marketplaces and Telegram channels. Its main focus is on offensive activities, such as crafting spear phishing emails, creating cracking tools, and engaging in carding activities. The tool has been available since at least July 22, 2023, with subscription costs ranging from $200 a month to $1,700 for a year.
<br/>
The author, known as CanadianKingpin, claims that FraudGPT offers exclusive tools and capabilities, including the ability to write malicious code, create undetectable malware, and find leaks and vulnerabilities. According to the author, there have been over 3,000 confirmed sales and reviews of the tool. The specific large language model (LLM) used to develop FraudGPT is currently unknown.
<br/>
<Image src="/gpt.jpg" alt="" width={600} height={500} />
<br />
This development is part of a concerning trend, where threat actors are leveraging OpenAI ChatGPT-like tools to create new variants specifically designed for cybercriminal activities without any restrictions. These tools not only enable phishing-as-a-service (PhaaS) but also facilitate large-scale phishing and business email compromise (BEC) attacks, leading to the theft of sensitive information and unauthorized wire payments.
<br/>
The article emphasizes that while organizations can develop ChatGPT and similar tools with ethical safeguards, cybercriminals can easily reimplement the technology without such restrictions. Thus, implementing a defense-in-depth strategy with robust security telemetry becomes crucial to detect and prevent fast-moving threats before they cause significant harm, such as turning phishing emails into ransomware attacks or data exfiltration incidents.
<br/>
<Button
  address="https://thehackernews.com/2023/07/new-ai-tool-fraudgpt-emerges-tailored.html?ref=futuretools.io"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***Escalating China-Taiwan Tensions Fuel Alarming Surge in Cyber Attacks***
<br/>
<Image src="/china-taiwan-cyberattacks.png" alt="" width={600} height={500} />
<br />
Geopolitical tensions between China and Taiwan have led to a significant increase in cyber attacks on Taiwan. The Trellix Advanced Research Center reported that the strained relationship, with China claiming Taiwan as its territory and Taiwan asserting its independence, has resulted in a surge of attacks. These attacks, which occurred between April 7 and April 10, 2023, targeted various sectors and were primarily aimed at delivering malware and stealing sensitive information. Malicious emails saw a four-fold increase during this period, affecting industries such as networking, manufacturing, and logistics.
<br/>
Following the spike in malicious emails, there was a 15x rise in detections of the PlugX remote access trojan between April 10 and April 12, 2023. This indicates that phishing lures served as initial access points for more significant attacks. PlugX is a Windows backdoor utilized by Chinese threat actors to gain control over victim machines discreetly.
<br/>
Trellix also identified other malware families like the Kryptik trojan, as well as stealers like Zmutzy and FormBook, targeting Taiwan. Socially engineered messages contained links to seemingly harmless login pages mimicking legitimate brands, including DHL, in an attempt to trick users into giving up their credentials.
<br/>
Geopolitical conflicts have increasingly become driving factors behind cyber attacks on various industries and institutions, emphasizing the need for organizations to monitor such events to predict potential cyber threats in countries where they operate.
<br/>
<Button
  address="https://thehackernews.com/2023/05/escalating-china-taiwan-tensions-fuel.html"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***OpenAI Reveals Redis Bug Behind ChatGPT User Data Exposure Incident***
<br/>
On March 20, 2023, OpenAI reported a bug in the Redis open source library that caused a data security breach in its ChatGPT service. The glitch allowed certain users to see brief descriptions of other users' conversations from the chat history sidebar, leading to the temporary shutdown of the chatbot. The bug was traced back to the redis-py library, which corrupted connections and returned unexpected data from the database cache, exposing information belonging to unrelated users. OpenAI accidentally introduced a server-side change that increased request cancellations, exacerbating the issue.
<br/>
As a result of this bug, approximately 1.2% of ChatGPT Plus subscribers may have had their payment-related information exposed, including names, email addresses, payment addresses, the last four digits of credit card numbers, and credit card expiration dates. However, full credit card numbers were not compromised. OpenAI promptly addressed the problem, notifying affected users and implementing redundant checks to prevent similar incidents in the future.
<br/>
In addition to the Redis bug, OpenAI also fixed a critical account takeover vulnerability discovered by a security researcher named Gal Nagli. This flaw allowed attackers to seize control of other users' accounts, access their chat history, and view billing information without their knowledge. OpenAI resolved this issue swiftly after responsible disclosure by Nagli.
<br/>
The incidents underscore the importance of robust data security measures in Artificial Intelligence systems and the need for continuous vigilance to protect user information.
<br/>
<Button
  address="https://thehackernews.com/2023/05/escalating-china-taiwan-tensions-fuel.html"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Protect AI raises $35M to build a suite of AI-defending tools***
<br/>
<Image src="/GettyImages-1300897309.jpeg" alt="" width={600} height={500} />
<br />
Protect AI, a startup focused on bolstering the security of AI systems, has secured $35 million in a Series A funding round, led by Evolution Equity Partners and featuring participation from Salesforce Ventures, Acrew Capital, boldstart ventures, Knollwood Capital, and Pelion Ventures. This new funding round is more than twice the size of their previous seed round, bringing the total raised to $48.5 million. Protect AI plans to utilize the funds to enhance its platform's capabilities, expand research efforts, and launch new open-source projects. The company's CEO, Ian Swanson, revealed that the capital will also allow them to grow their workforce from 25 to 40 employees by the end of the year.
<br/>
Protect AI, co-founded by Ian Swanson and Daryan Dehghanpisheh in 2022, aims to address the security risks inherent in AI systems as they become more widely adopted, especially in sensitive industries like finance and healthcare. Their flagship tool, AI Radar, offers visibility into AI model components, data used for training, testing datasets, and code, generating a "machine learning bill of materials" to identify potential vulnerabilities and risks in the supply chain. The startup also offers tools to counter specific AI attacks, such as prompt injection attacks.
<br/>
While Protect AI faces competition in the emerging AI security tools market, the company claims to have attracted high-profile private and public sector customers in finance, healthcare, life sciences, and energy. With the increase in cyberattacks targeting supply chains and growing concerns over privacy and security, Protect AI aims to play a significant role in securing the AI-powered world.
<br/>
<Button
  address="https://techcrunch.com/2023/07/26/protect-ai-raises-35m-to-build-a-suite-of-ai-defending-tools/"
  text="Source"
/>
