---
title: "OpenAI wants teachers to use ChatGPT for education"
layout: "Article"
tags:
  -AI 
  -IT
  -News
excerpt:
publishedAt:
---
<br/>
OpenAI is showcasing the versatile applications of its language models, including GPT-3, GPT-3.5, and GPT-4, beyond programming, journalism, and content moderation. The company has released a blog post titled "Teaching with AI," featuring examples of six educators from various countries who have integrated ChatGPT into their classrooms to enhance student learning. These educators use ChatGPT in diverse ways: as an educational role player for debates, a translation assistant for ESL students, and a source for information fact-checking.
<br/>
OpenAI also provides sample prompts developed by educators Ethan Mollick and Lilach Mollick to help teachers integrate ChatGPT into lesson planning and even transform it into an "AI tutor" for students. The company clarifies that it did not pay Ethan Mollick for the use of his prompts, as they utilized already published materials.
<br/>
Despite the potential benefits, the use of generative AI like ChatGPT in classrooms has sparked controversy. Some institutions have banned its use due to concerns about students exploiting it to bypass coursework, such as essay writing. OpenAI acknowledges the challenges of detecting AI-generated content and points out that even if detection tools improve, students can make minor edits to evade detection. OpenAI suggests that educators encourage critical thinking by having students demonstrate their interactions with ChatGPT as a display of their skills.
<br/>
OpenAI emphasizes that ChatGPT can complement teachers' efforts in providing feedback and aiding students' learning, but it cautions against relying solely on AI models for assessment decisions. The company's intention is to present ChatGPT as a helpful tool for teachers and students alike, rather than a complete replacement for traditional educational methods. While the integration of AI in education holds promise, OpenAI underscores the importance of maintaining a "human in the loop" approach for meaningful learning experiences.
<br/>
<Button
  address="https://venturebeat.com/ai/openai-wants-teachers-to-use-chatgpt-for-education/"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***IBM and Salesforce team up to bring AI tools to their shared clients***
<br/>
IBM and Salesforce have announced a collaboration to offer AI solutions to their shared customers. Salesforce, known for its CRM software and AI tools like Sales GPT, Service GPT, Salesforce Einstein, Slack GPT, and Marketing GPT, will now join forces with IBM to provide integrated AI solutions. IBM, with its industry expertise and 160,000 human consultants from IBM Consulting, aims to assist clients in implementing these AI integrations effectively.
<br/>
IBM's offerings include the "IBM Garage," a business transformation operating model that aids clients in getting their Salesforce AI integrations up and running smoothly. Additionally, IBM suggests that shared customers consider using its WatsonX enterprise AI platform, which can help identify and optimize enterprise-grade AI models, as well as access data from backend systems for better utilization with Salesforce and open-source AI models.
<br/>
IBM's Data Classifier, an AI-powered application trained on industry-specific data models, can help customers map their internal data to make it usable and accessible for AI tools and applications. This collaboration aims to transform how companies engage with customers by leveraging generative AI technologies.
<br/>
Salesforce's EVP and GM of global alliances and channels, Steve Corfield, emphasizes the importance of partners like IBM Consulting in helping businesses utilize Salesforce's AI, data, and CRM technologies to connect with customers on a deeper level. IBM's own adoption of Salesforce and watsonx for customer service and sales processes showcases their commitment to this transformative approach.
<br/>
This partnership signifies a strategic alignment between two major tech players, combining Salesforce's CRM dominance and AI tools with IBM's industry expertise and consulting capabilities. The aim is to empower companies to deliver personalized and engaging experiences by harnessing the potential of AI and data-driven insights.
<br/>
<Button
  address="https://venturebeat.com/ai/ibm-and-salesforce-team-up-to-bring-ai-tools-to-their-shared-clients/"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Malicious npm Packages Aim to Target Developers for Source Code Theft***
<br/>
A recent report from software supply chain security firm Checkmarx highlights an ongoing threat campaign exploiting malicious npm packages to compromise developers' machines. This campaign, attributed to a threat actor with a history dating back to 2021, demonstrates a persistent menace within open-source repositories. The attacker's primary objective is to pilfer source code and configuration files from victim systems.
<br/>
These malicious npm packages are designed to execute post-installation via a postinstall hook defined in the package.json file. This execution chain ultimately results in the extraction of system metadata, source code, and sensitive data from specific directories. The stolen information is then archived into a ZIP file and transmitted to a predefined FTP server. A notable identifier of these packages is the consistent use of "lexi2" as the author in the package.json file.
<br/>
While the exact motivations behind this campaign remain unclear, the naming conventions of some packages, such as "binarium-client," "binarium-crm," and "rocketrefer," suggest a focus on the cryptocurrency sector. Security researchers emphasize that the cryptocurrency industry continues to be a prime target for cyberattacks, not only from malicious packages but also from persistent adversaries with well-planned, long-running operations.
<br/>
This report underscores the ongoing challenges in safeguarding open-source repositories and the critical need for developers and organizations to maintain vigilance and adopt robust security measures to protect against threats that persistently target software supply chains. The threat landscape continues to evolve, and adversaries are becoming more resourceful and persistent, making proactive security practices essential for defending against such attacks.
<br/>
<Button
  address="https://thehackernews.com/2023/08/malicious-npm-packages-aim-to-target.html"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Meta releases a dataset to probe computer vision models for biases***
<br/>
Meta has introduced a new open-source AI benchmark called FACET (FAirness in Computer Vision EvaluaTion) aimed at assessing the fairness of AI models used in image and video classification. FACET contains 32,000 images featuring 50,000 individuals, labeled for various demographic attributes, physical characteristics, and occupations. This benchmark enables deep evaluations of biases, including gender and other demographic factors, allowing researchers and practitioners to scrutinize AI models for fairness concerns.
<br/>
While Meta's past record in responsible AI has been criticized, FACET is presented as a more comprehensive benchmark than its predecessors. It delves into questions like whether models tend to stereotype individuals based on their gender presentation or other physical attributes, highlighting potential biases. To create FACET, Meta employed trained annotators from various regions, compensating them with country-specific hourly wages. However, questions remain about how the annotators were recruited and whether individuals pictured in the images were informed of their usage.
<br/>
FACET can be used to test classification, detection, instance segmentation, and visual grounding models across different demographic attributes. When applied to Meta's DINOv2 computer vision algorithm, it identified biases, including gender presentation and stereotypical associations, demonstrating the benchmark's effectiveness in uncovering biases in AI models.
<br/>
Meta acknowledges that FACET may not fully capture real-world concepts and that the dataset's depictions of professions may have changed since its creation. Despite these limitations, the benchmark and a web-based dataset explorer tool are available for evaluation, testing, and benchmarking purposes. However, developers are prohibited from training AI models using FACET to avoid potential biases perpetuated by the dataset.
<br/>
<Button
  address="https://techcrunch.com/2023/08/31/meta-releases-a-data-set-to-probe-computer-vision-models-for-biases/"
  text="Source"
/>