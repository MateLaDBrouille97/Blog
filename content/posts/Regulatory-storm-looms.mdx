---
title: "Regulatory storm looms: Europe and the US challenge tech giants' dominance"
layout: "Article"
tags:
  -AI 
  -IT
  -Geopol

excerpt:
publishedAt:
---
<br/>
The tech giants, including Google, Meta (formerly Facebook), Microsoft, Amazon, Apple, and others, have thrived for decades in a regulatory environment that largely left them unchecked. However, a global shift in regulatory attitudes is now challenging their unchecked power. In the European Union (EU), significant legislation like the Digital Services Act (DSA) and the upcoming Digital Markets Act (DMA) are set to impose strict regulations on major tech platforms, limiting their control over personal data, product exclusivity, and advertising practices. These regulations are poised to impact companies like Google, Meta, Apple, Microsoft, and Amazon significantly.
<br/>
Meanwhile, in the United States, the Department of Justice's antitrust trial against Google is underway. The case questions whether Google achieved its dominant position by anti-competitive practices, specifically in the search engine market. A victory for the Department of Justice could lead to Google's dissolution or substantial changes in its operations. This case represents the first significant federal antitrust challenge against a tech giant since the 1998 case against Microsoft.
<br/>
These regulatory efforts are significant because they could reshape the tech industry's landscape, moving beyond challenging mergers and acquisitions to addressing the fundamental mechanisms that allowed tech giants to accumulate immense power. However, they also face challenges in the U.S. legal system, which traditionally views antitrust issues primarily through the lens of consumer welfare, making it difficult to challenge companies that offer free services. Success in changing this perspective could lead to a broader overhaul of antitrust regulations, better adapted to the challenges of the modern digital age.
<br/>
<Button
  address="https://www.calcalistech.com/ctechnews/article/xxxu7ujxu"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***Europe In The Lead In AI Regulation***
<br/>
The article discusses the increasing importance of geopolitics in the world of technology, with a focus on Artificial Intelligence (AI). It begins by highlighting the current state of Northern Ireland, where the local economy is strong despite political challenges. The author notes that geopolitical risks are rising globally, citing the "Chip Wars" between China and the USA as an example. 
<br/>
The author then emphasizes the lack of interest in geopolitics among European companies, despite the growing importance of geopolitical factors in the markets. They mention that globalization has historically reduced the impact of geopolitical risk on markets, but recent events like Brexit and the Trump trade war have changed that landscape. Additionally, rising inflation and the absence of quantitative easing have made markets more sensitive to geopolitical risks.
<br/>
In this multipolar world, the article identifies several geopolitical risks, including the potential re-election of Donald Trump and China's expanding influence in Europe's technology sector. The author points out that how governments respond to landmark technologies like AI can shape the future industries.
<br/>
The article discusses the EU AI Act, which categorizes AI applications into four pillars based on their potential harm. It mentions that Europe's early move in AI regulation sets the standard for other regulatory initiatives worldwide. However, there is confusion about how companies not generating AI content but involved in its processes will be regulated under the AI Act.
<br/>
The author also highlights concerns about AI innovation among start-up firms, particularly in France, and the need for a regulatory sandbox system to balance innovation and regulation. Governance structures for AI regulation at both the EU and national levels remain unclear, with potential for individual state AI Offices or sub-sector AI Offices.
<br/>
Finally, the article notes the UK's ambition to become a global hub for AI regulation and suggests that the UK could host an international regulatory body for AI standards, similar to how Geneva hosts international organizations like the WHO and WTO.
<br/>
In summary, the article underscores the increasing role of geopolitics in AI regulation and the need for clarity in governance and regulation as AI continues to reshape industries and economies worldwide.
<br/>
<Button
  address="https://www.forbes.com/sites/mikeosullivan/2023/09/09/europe-in-the-lead-in-ai-regulation/?sh=3c7046f153c6"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***From China to Brazil, hereâ€™s how AI is regulated around the world***
<br/>
Artificial intelligence (AI) is rapidly transitioning from the realm of computer science textbooks to the mainstream, offering both exciting possibilities and potential disruptions. While AI has the potential to revolutionize fields like healthcare and weather prediction, it also raises concerns about job displacement and the emergence of superintelligent entities.
<br/>
A recent Pew Research Center survey indicates that 52% of Americans feel more concerned than excited about the increased use of AI, citing worries about personal privacy and control over AI technologies. The proliferation of generative AI models like ChatGPT and others has brought AI to the forefront of public awareness, prompting governments worldwide to grapple with harnessing its transformative power while regulating its use.
<br/>
Several countries are taking varying approaches to AI regulation:
<br/>
1. Brazil has proposed a comprehensive AI law focused on users' rights, demanding transparency and human intervention when necessary, along with risk assessments for AI products.
<br/>
2. China has released draft regulations for generative AI and emphasizes adherence to "Socialist Core Values," focusing on developer responsibility and content accuracy.
<br/>
3. The European Union has passed the AI Act, categorizing AI as unacceptable, high risk, or limited risk, with corresponding levels of regulation.
<br/>
4. Israel's draft policy centers on "responsible innovation," emphasizing human rights and public interests, advocating for self-regulation and sector-specific interventions.
<br/>
5. Italy briefly banned ChatGPT over data collection concerns and allocated funds to support workers affected by automation, emphasizing digital skills training.
<br/>
6. Japan and Israel have adopted a "soft law" approach, avoiding prescriptive regulations to encourage innovation.
<br/>
7. The United Arab Emirates aims to develop AI while forming an AI and Blockchain Council to oversee issues like data management and cybersecurity.
<br/>
Despite global efforts, concrete AI regulations remain scarce. The debate continues on how to strike the right balance between harnessing AI's potential and mitigating its risks, from privacy concerns to the potential for superintelligent AI entities. Different countries are navigating these challenges with varying levels of urgency and regulatory approaches.
<br/>
<Button
  address="https://www.washingtonpost.com/world/2023/09/03/ai-regulation-law-china-israel-eu/"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Ted Lieu dishes on how Congress can get savvy on AI regulation***
<br/>
Rep. Ted Lieu of California advocates for creating a commission to study artificial intelligence (AI) and provide lawmakers with guidance on regulating this rapidly advancing technology. He believes that while legislators don't need to be tech experts, they shouldn't regulate AI in isolation without expert input. Lieu highlights that the complexity of AI and its potential consequences necessitate informed decision-making.
<br/>
His proposed legislation, H.R. 4223, co-sponsored by Reps. Ken Buck and Anna Eshoo, aims to establish a blue-ribbon commission to study AI and offer recommendations for regulation. Lieu argues that Congress lacks the capacity to comprehensively regulate AI across various applications, emphasizing the need for expert guidance.
<br/>
Lieu also draws parallels with the Food and Drug Administration (FDA) model, where Congress sets standards, and specialized agencies implement regulations. He believes that Congress should outline AI standards and principles, leaving federal agencies to regulate specific industries.
<br/>
While Lieu supports creating an AI commission, he emphasizes the importance of immediate action on certain AI-related issues. He calls for legislation prohibiting the use of fully autonomous nuclear weapons by the U.S. military, a measure he deems straightforward and essential.
<br/>
Additionally, Lieu proposes banning the use of AI-generated deepfakes in political elections, asserting that AI is a tool with both positive and negative potential, making AI-related issues non-partisan.
<br/>
In the Senate, Majority Leader Chuck Schumer is also focusing on AI through forums with tech experts, with an emphasis on national security, privacy, and copyrights. Legislation on AI is seen as challenging but necessary, given its transformative potential in various sectors.
<br/>
Ted Lieu's push for an AI commission reflects the recognition that AI regulation requires expertise, and he seeks to balance congressional oversight with specialized guidance in shaping AI policy.
<br/>
<Button
  address="https://www.politico.com/news/2023/09/07/ai-regulation-ted-lieu-00114411"
  text="Source"
/>
