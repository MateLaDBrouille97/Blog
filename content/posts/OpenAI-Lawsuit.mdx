---
title: "OpenAI Lawsuit: John Grisham, George R.R. Martin, and MORE Join the Fight against AI"
layout: "Article"
tags: 
  -AI 
  -IT
  -News
excerpt:
publishedAt:
---
<br/>
OpenAI, a prominent AI company, is currently embroiled in a lawsuit filed by renowned authors, including John Grisham, George R.R. Martin, Jodi Picoult, and more. These authors have joined forces with the Authors Guild to take legal action against OpenAI for allegedly illegally using their literary works to train its large-language models (LLMs), such as ChatGPT.
<br/>
The lawsuit revolves around the accusation that OpenAI used pirated versions of the authors' compositions to train its AI models, thereby violating copyright laws. These authors argue that creators should have the right to decide whether their works are used to train AI and, if so, they should be fairly compensated.
<br/>
The Authors Guild and the authors claim that OpenAI harvested a vast library of internet content, including their literary creations, to train LLMs, which power various programs like ChatGPT. Additionally, they assert that the AI could mimic or paraphrase their content and distribute it for free or at a minimal cost.
<br/>
This lawsuit is part of a broader pattern of AI technology facing legal challenges over the alleged unauthorized use of artists' works. The internet's vast repository of creative content has made it a prime target for AI training data, but such usage is subject to intellectual property laws.
<br/>
Notably, another class-action lawsuit has been initiated against Meta and OpenAI, led by comedian Sarah Silverman, highlighting the growing legal scrutiny facing AI companies.
<br/>
While OpenAI remains a prominent name in the AI industry, it is not alone in facing these allegations. The authors' lawsuit is part of a broader movement in which renowned writers are taking a stand against AI companies like OpenAI for their alleged role in appropriating their creative works for training AI models.
<br/>
<Button
  address="https://techcrunch.com/2023/09/21/youtube-to-add-ai-creator-tools-to-find-music-for-videos-add-dubs/"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***Prominent Authors, Including George R.R. Martin, John Grisham, Launch Class-Action Lawsuit Against OpenAI***
<br/>
A group of renowned authors, including George R.R. Martin, John Grisham, and Jodi Picoult, has filed a class-action lawsuit against OpenAI, a leading artificial intelligence organization, alleging that OpenAI unlawfully used their copyrighted works to train its popular AI chatbot, ChatGPT. The Authors Guild, a professional association representing writers, is spearheading this legal action, claiming that OpenAI engaged in "systematic theft on a mass scale" by copying the authors' intellectual property without permission or compensation.
<br/>
Central to the lawsuit is the argument that ChatGPT poses a significant threat to fiction writers' livelihoods. The Authors Guild contends that OpenAI had alternatives, such as using public domain works or compensating authors, but chose not to pursue them.
<br/>
The lawsuit seeks unspecified actual damages, with the possibility of statutory damages that could reach up to $150,000 for each infringed work. This could have substantial financial implications for OpenAI.
<br/>
OpenAI has defended its position by claiming that its use of training data scraped from the internet falls under fair use provisions of U.S. copyright law. The outcome of this lawsuit could hinge on the interpretation of fair use in the context of AI training.
<br/>
Specific examples of alleged infringements are included in the lawsuit, such as ChatGPT generating an unauthorized outline for a prequel to George R.R. Martin's "A Game of Thrones." These instances highlight the potential for AI-generated content to mimic established authors' works.
<br/>
OpenAI has responded by stating its respect for authors' rights and its willingness to engage in discussions with creators worldwide, including the Authors Guild. This lawsuit is part of a broader trend of legal actions by writers and artists against generative AI providers. The outcome will shape the future of AI content generation and copyright issues in the digital age.
<br/>
<Button
  address="https://www.techtimes.com/articles/296648/20230921/prominent-authors-including-george-r-martin-john-grisham-launch-class-action-openai.htm"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Authors File Lawsuit Against OpenAI For Using Copyrighted Books for Training Without Permission***
<br/>
OpenAI, the organization behind the AI tool ChatGPT, is facing a lawsuit filed by authors Mona Awad and Paul Tremblay. They allege that OpenAI violated copyright law by training ChatGPT on their novels without obtaining permission. This marks the first copyright complaint against ChatGPT and could set legal precedents for the use of copyrighted material in training language models.
<br/>
ChatGPT, a chatbot known for generating human-like responses, is trained using publicly available internet data. The authors claim that ChatGPT produced accurate summaries of their copyrighted books, leading to the lawsuit. Their lawyers argue that OpenAI should be held responsible for profiting from the unauthorized use of their work.
<br/>
Proving direct financial losses due to ChatGPT's training on copyrighted material may be challenging. ChatGPT relies on a wide range of internet information, including discussions about books, making it difficult to quantify the impact.
<br/>
OpenAI's secrecy regarding its training data has also come under scrutiny. It's suggested that ChatGPT's training material, referred to as "Books2," may include books from shadow libraries like Library Genesis and Z-Library. The case's outcome will depend on whether the court considers "fair use" in the context of copyright material usage, which may differ from UK law.
<br/>
This lawsuit reflects broader concerns in the publishing industry about protecting authors from potential AI-related harms. The Society of Authors has published guidelines to help authors safeguard their work. The case against OpenAI is viewed as a positive step in addressing these concerns.
<br/>
Despite existing laws, regulations struggle to keep up with technological advancements. Policymakers are urged to consult principles that protect human authorship's value and consider recommendations from organizations like the Authors' Licensing and Collecting Society. OpenAI's legal challenges highlight the need for clearer guidelines in the AI field.
<br/>
<Button
  address="https://www.techtimes.com/articles/293475/20230705/authors-file-lawsuit-against-openai-using-copyrighted-books-ai-training.htm"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***FBI Echoes Warning on Danger of Artificial Intelligence***
<br/>
FBI Director Christopher Wray issued a warning about the potential abuses of artificial intelligence (AI) at a cybersecurity conference in Washington. He expressed concerns that criminals and hostile foreign governments are already exploiting AI technology, though he did not provide specific examples. Wray highlighted the dual nature of AI, which can benefit law-abiding citizens by automating tasks but also empower malicious actors to create deepfakes and malicious code.
<br/>
The FBI is actively working to identify and track those using AI to harm U.S. citizens while carefully considering the ethical and legal implications of employing AI themselves. Other U.S. national security agencies, such as the Department of Homeland Security (DHS), are already utilizing AI for various purposes, including combating drug trafficking, countering child exploitation, and safeguarding critical infrastructure. DHS is also implementing guidelines to ensure transparency and protect civil rights.
<br/>
However, the fear of AI's potential for harm is growing across U.S. government departments. The FBI previously warned that violent extremists and terrorists are experimenting with AI for building explosives, and criminals are increasingly turning to AI for various illegal activities. China is a major source of concern, with National Security Agency officials noting that Beijing has been using AI for propaganda dissemination. Private cybersecurity companies, like Microsoft, have also raised alarms about Chinese-linked cyber actors using AI for disinformation campaigns.
<br/>
China has denied allegations of using AI improperly, particularly in creating fake social media accounts for propaganda purposes. They consider such accusations as prejudiced and speculative. As AI technology continues to advance, the United States faces both opportunities and threats, emphasizing the need for responsible and ethical AI development and usage in the face of evolving challenges.
<br/>
<Button
  address="https://www.voanews.com/a/fbi-echoes-warning-on-danger-of-artificial-intelligence-/7273751.html"
  text="Source"
/>
