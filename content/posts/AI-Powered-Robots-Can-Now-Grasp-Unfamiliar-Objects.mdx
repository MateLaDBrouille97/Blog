---
title: "AI-Powered Robots Can Now Grasp Unfamiliar Objects Using Natural Language"
layout: "Article"
tags: 
  -AI 
  -IT
  -Opinions
excerpt:
publishedAt:
---
<br/>
Researchers at MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a system called Feature Fields for Robotic Manipulation (F3RM) that enables robots to grasp and manipulate objects using open-ended language prompts. Inspired by human flexibility, F3RM allows robots to identify, comprehend, and engage with unfamiliar objects. The system creates complex 3D environments by combining basic model characteristics with 2D photos. F3RM has various applications, particularly in settings like homes and warehouses where there are many objects. It enables robots to efficiently complete tasks and interpret ambiguous human demands, improving their flexibility and human-like interaction.
<br/>
F3RM can be particularly useful in fulfillment centers, where robots often need to match textual inventory descriptions to items, regardless of differences in packaging. The system's spatial and semantic perception skills help robots accurately locate items, place them in designated bins, and prepare them for packing, enhancing order fulfillment, efficiency, and customer satisfaction.
<br/>
The scene comprehension feature of F3RM makes it applicable in different contexts, such as customized robots recognizing and retrieving specific objects. The technology enables robots to interact with their environment physically and perceptually. The system starts by taking multiple pictures, which are used to create a 3D scene using a deep learning technology called Neural Radiance Field (NeRF). F3RM goes beyond generating a 3D model by creating a feature field enhanced with semantic data from a vision model called CLIP. This allows F3RM to understand visual concepts and improve comprehension of the environment's geometry and semantics.
<br/>
With F3RM's open-ended features, robots can respond to human queries and choose and interact with objects based on vague descriptions, similar to how humans would. The system's flexibility and problem-solving abilities were tested by having a robot pick up an object it had not specifically been taught to handle, demonstrating its adaptability and real-time perception capabilities.
<br/>
F3RM's innovative approach enables robots to perform dynamic control tasks and generalize from a small set of demonstrations by combining geometric knowledge with semantics from foundation models trained on a large data set. Overall, F3RM enhances robots' manipulation abilities and their ability to interact with the world in a more human-like manner.
<br/>
<Button
  address="https://www.techtimes.com/articles/298376/20231106/mit-unveils-f3rm-ai-powered-robots-now-grasp-unfamiliar-objects.htm"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***Tiny Soft Robots Designed for Delicate Medical Procedures Are Uniquely Made From Plant-Based Hydrogel***
<br/>
Researchers from the University of Waterloo have developed advanced materials that could be used in the next generation of soft medical microbots. These tiny robots, measuring just one centimeter in length, have the potential to perform a wide range of medical procedures in a minimally invasive manner. The soft robots are biocompatible and non-toxic, making them suitable for medical applications. The robots are made from advanced hydrogel composites that incorporate sustainable cellulose nanoparticles derived from plants, demonstrating a forward-thinking approach to materials sourcing.
<br/>
The hydrogel used in the robots has a unique responsiveness to external chemical stimuli, allowing for controlled alterations of shape and enabling the robots to adapt to various medical procedures. The material is also self-healing, meaning it can be severed and seamlessly rejoined without the need for adhesives or glue. Additionally, the material can be endowed with magnetic properties, enhancing the mobility of the robots within the human body.
<br/>
The researchers successfully guided the robots through a maze using controlled magnetic guidance, demonstrating their maneuverability. The next phase of the research is to downsize the robots to submillimeter dimensions.
<br/>
The development of these advanced materials for soft medical microbots has the potential to revolutionize medical procedures. The robots can perform tasks such as biopsies and transporting cells and tissues, all in a minimally invasive manner. By utilizing sustainable and biocompatible materials, the robots can be safely used in the human body without causing harm. The responsiveness and self-healing properties of the hydrogel make it an ideal material for creating adaptable robots that can navigate complex environments. The addition of magnetic properties further enhances the robots' mobility. Overall, this breakthrough in advanced materials opens up new possibilities for the future of medical robotics.
<br/>
<Button
  address="https://www.techtimes.com/articles/297896/20231024/plant-based-hydrogel-used-tiny-soft-robots-medical-procedures.htm"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Robot Guide Dog Responding to Tugs on Its Leash Could Help Blind and Visually Impaired People***
<br/>
Scientists at Binghamton University in New York have developed a robotic guide dog to assist people with visual impairments. The robot responds to tugs on its leash, and in a demonstration, it successfully led a person through a hallway with confidence and attentiveness. The motivation behind the project was the low accessibility of guide dogs for visually impaired individuals. Currently, only 2% of visually impaired individuals have access to a guide dog for their entire lifetime, due to the high cost and lengthy training period of real guide dogs. These challenges could be addressed by robotic guide dogs, which are more cost-effective, efficient, and accessible. The team spent a year developing a unique interface based on leash tugging, which allows users to guide the robot's movement in a specific direction. However, further research and development are needed before the technology can be deployed in various environments. The team plans to add a natural language interface and train the robot to disobey certain commands in potentially dangerous situations. They are actively seeking feedback from the visually impaired community to refine their research, and they anticipate that the robots may excel in specific environments by storing maps of complex spaces. While still in its early stages, this research is seen as a significant step towards improving accessibility for the visually impaired community in public spaces.
<br/>
<Button
  address="https://www.techtimes.com/articles/298146/20231031/robot-guide-dog-responding-tugs-leash-help-blind-visually-impaired.htm"
  text="Source"
/>