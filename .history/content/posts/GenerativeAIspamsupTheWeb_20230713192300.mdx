---
title: "The week in AI: Generative AI spams up the web"
layout: "Article"
tags:
  -AI 
  -IT
  -News
  -Generative AI
  -Week in AI
 
excerpt:
publishedAt:
---
<br/>
In the world of AI and machine learning, generative AI is starting to change the landscape of the web. SpeedyBrand, a company backed by Y Combinator, uses generative AI to create SEO-optimized content, but it has raised concerns about the proliferation of low-quality, AI-generated content and misinformation on the internet. Advertisers are facing challenges as their ads appear on junk news sites created with generative AI, impacting their brand reputation and potentially diverting advertising money from legitimate sites.
<br/>
The solution to this problem is uncertain. Some suggest that search engines and ad platforms should exercise stricter control and penalize bad actors using generative AI. However, the rapidly evolving nature of the field and the scalability of generative AI make it difficult to keep up with the problem.
<br/>
The barrier to entry for generating spammy content using AI is low, both in terms of cost and time invested, which is a significant difference from previous waves of spam on the web. While some remain optimistic that this influx of AI-generated junk content could lead to the development of better-funded platforms, the decisions made now regarding generative AI and its outputs will have a lasting impact on the web.
<br/>
In other AI news, OpenAI has officially launched GPT-4, an advanced text-generating model. OpenAI is also forming a new team to develop ways to steer and control "superintelligent" AI systems. New York City has started enforcing an anti-bias law requiring employers to submit their AI algorithms for independent audits. Valve has tacitly approved AI-generated games for its Steam games store, and Humane has unveiled its first product, the Ai Pin, a wearable gadget with AI-powered features.
<br/>
Furthermore, researchers from ETH Zurich have developed an AI system for smart intubation and contributed to Pixar's movie "Elemental" by pioneering technology to animate smoke and fire. AI has also been used to identify new Nasca lines in Peru and predict natural disasters like wildfires and landslides. Google is exploring the challenge of teaching machine learning systems without propagating dangerous knowledge, while researchers discuss the psychological aspects of trust in AI models. Additionally, an article explores the history of mechanical chess players and their relation to computer games.
<br/>
<Button
  address="https://techcrunch.com/2023/07/08/the-week-in-ai-generative-ai-spams-up-the-web/"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
### ***Anthropic releases Claude 2, its second-gen AI chatbot***
<br/>
<Image src="/anthropic-header.jpg" alt="" width={600} height={500} />
<br/>
Anthropic, an AI startup founded by former executives from OpenAI, has introduced Claude 2, a new text-generating AI model. Available in beta in the U.S. and U.K., Claude 2 offers improvements over its predecessor, Claude 1.3. It performs better on various tasks, such as scoring higher on multiple-choice tests, excelling in Python coding, and answering math problems more accurately. Claude 2 was trained on more recent data and benefits from a large context window of 100,000 tokens, allowing it to generate around 3,125 words. Anthropic has been focused on improving the model's reasoning and self-awareness, making it more capable of processing multi-step instructions while being aware of its limitations.
<br />
However, like other AI models, Claude 2 still has limitations and potential risks. It may produce irrelevant or incorrect responses and generate toxic or biased text. Anthropic claims that Claude 2 is "2x better" at giving harmless responses and is less likely to provide biased answers compared to Claude 1.3. The company has implemented constitutional AI principles to guide Claude 2's behavior, but acknowledges the challenges in predicting its behavior in all scenarios. Anthropic advises against using Claude 2 in high-stakes situations or applications involving physical or mental health and well-being.
<br/>
Anthropic, which competes with OpenAI and other startups, plans to create a next-generation algorithm for AI self-teaching. The company has raised $1.45 billion in funding, including investments from Google, and estimates it will require $5 billion over the next two years to develop its envisioned chatbot. By releasing beta models like Claude 2, Anthropic aims to generate incremental revenue and further advance its development while offering its AI models through various platforms and partnerships.
<br/>
<Button
  address="https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot/"
  text="Source"
/>
<br/>
<br/>
<br/>
### ***Googleâ€™s AI-assisted note-taking app gets limited launch as NotebookLM***
<br/>
<Image src="/google.jpg" alt="" width={600} height={500} />
<br/>
Google has renamed its "AI notebook for everyone" from Project Tailwind to NotebookLM and is making it available to a limited number of users. The project aims to help students organize their lecture notes and documents using artificial intelligence. Unlike generic chatbots, NotebookLM focuses on analyzing and answering questions based on the specific documents it is provided. It prioritizes recently accessed information but can also retrieve additional knowledge if needed. Google emphasizes the need to fact-check the AI's responses against personal notes. While the purpose and target audience of NotebookLM are still unclear, Google hopes to gather feedback and improve the product's usefulness.
<br/>
<Image src="/DocumentGuide-Keyword-V2.width-1000.jpg" alt="" width={600} height={500} />
<br/>
<Button
  address="https://techcrunch.com/2023/07/12/googles-ai-assisted-note-taking-app-gets-limited-launch-as-notebooklm/"
  text="Source"
/>
<br/>
<br/>
<br/>
### ***Three months of AI in six charts***
<br/>
<Image src="/software-Tech.jpg" alt="" width={600} height={500} />
<br/>
The past three months in the world of AI have been eventful. OpenAI's Code Interpreter is making data science more accessible to non-coders, prompting a shift in data science education towards AI-guided programming. Chegg, an online education company, saw its stock price drop significantly due to generative AI's impact. Anthropic released a model called Claude with a large context window, enabling it to process longer texts and allowing for greater personalization.
<br/>
<Image src="/bdb9d1b2-e017-4f91-bdc7-954839699e6a_1446x1456.jpg" alt="" width={600} height={500} />
<br/>
AI was found to boost productivity and accelerate learning in some jobs. Open-source AI is gaining momentum, reducing training costs and fostering competition. Regulators in the US and Europe are considering regulations for AI, but there are concerns about the scope and timing of these rules. The future of AI remains uncertain, but the impact on wealth and power distribution is a concern for some.
<br/>
<Image src="/ea8f2987-0f97-4dc8-86b2-bdeed34ebc60_1472x614.jpg" alt="" width={600} height={500} />
<br/>
<Button
  address="https://www.exponentialview.co/p/q2-3-months-in-ai-in-6-charts"
  text="Source"
/>
