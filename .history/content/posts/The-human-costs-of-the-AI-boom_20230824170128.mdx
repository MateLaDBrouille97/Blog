---
title: "The human costs of the AI boom"
layout: "Article"
tags: 
  -Definition
  -IT
  -News
  -Tech
  -AI boom
excerpt:
publishedAt:
---
<br/>
Cloudwork platforms, where online remote work is outsourced, have gained significance due to their role in services provided by tech giants like OpenAI, Amazon, Microsoft, and Google. These platforms, such as Scale AI, Freelancer.com, and Upwork, offer outsourced labor for various tasks, including AI training, content moderation, translation, and graphic design. They provide a cost-effective and skilled workforce available around the clock, benefiting companies but potentially disadvantaging workers.
<br/>
While cloudwork presents earning opportunities for millions, the reality for workers can be challenging. Many tasks are low-paying and lack guarantees of minimum wage. Workers spend unpaid time seeking jobs, often with little recourse if problems arise. The Fairwork project assessed 15 platforms, including Amazon Mechanical Turk and Fiverr, on five principles of fair work: pay, conditions, contracts, management, and representation. No platform met even half of these standards, with average earnings for surveyed workers being a meager $2.15 USD per working hour.
<br/>
The international nature of this industry often allows platforms to bypass labor regulations, leading to insufficient worker protections. The rise in cloudwork is driven by AI companies and post-pandemic remote work trends. Some platforms, like Terawork and Comeup, have made improvements, including implementing minimum wage floors. However, comprehensive solutions require international labor standards and national government involvement. Although regulatory discussions often center on sectors like ride-hailing, addressing cloudwork challenges is equally crucial. The International Labour Organization's consideration of digital economy worker rights standards offers an opportunity, necessitating global cooperation for meaningful change.
<br/>
<Button
  address="https://techcrunch.com/2023/08/21/the-human-costs-of-the-ai-boom/"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***Meta releases an AI model that can transcribe and translate close to 100 languages***
<br/>
<Image src="/GettyImages-1256252051.jpeg" alt="" width={700} height={650} />
<br />
Meta has unveiled an AI model called SeamlessM4T, designed to comprehend a wide array of dialects and translate almost 100 languages through text and speech. This open-source initiative aims to facilitate more effective communication between people speaking different languages. Notably, SeamlessM4T identifies source languages without requiring a separate language identification model, representing a significant advancement in speech-to-speech and speech-to-text AI capabilities. The system builds upon Meta's Massively Multilingual Speech framework, which supports speech recognition, language identification, and speech synthesis across over 1,100 languages.
<br/>
While various entities, including Amazon, Microsoft, OpenAI, and Google, have been developing AI translation and transcription tools, SeamlessM4T stands out for integrating translation and transcription functionalities within a single model. The model was trained using publicly available text and speech data, which Meta claims to be non-copyrighted and predominantly sourced from open source or licensed platforms. SeamlessM4T's training dataset, SeamlessAlign, was created by aligning large amounts of speech with corresponding texts, allowing the model to learn speech-to-text transcription, translation, and speech generation tasks.
<br/>
Although SeamlessM4T presents a significant advancement, it carries certain biases and limitations. It can exhibit gender biases and other forms of bias found in AI translation models, impacting the accuracy and fairness of its translations. Additionally, the model's translations may lack the diverse lexical richness that human interpreters offer. Consequently, Meta advises against using SeamlessM4T for sensitive areas like medical and legal translations due to potential mistranslations. Despite its achievements, the model highlights the ongoing need for ethical considerations and human involvement in AI translation to ensure accurate, culturally sensitive communication.
<br/>
<Button
  address="https://techcrunch.com/2023/08/22/meta-releases-an-ai-model-that-can-transcribe-and-translate-close-to-100-languages/"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***AI2 drops biggest open dataset yet for training language models***
<br/>
The Allen Institute for AI (AI2) aims to counter the secrecy surrounding data used in training powerful language models like GPT-4 and Claude. They have released a massive text dataset called Dolma, intended to be the foundation for an open language model (OLMo) that researchers can freely use and modify. Unlike proprietary datasets from companies like OpenAI and Meta, Dolma's sources and processes are publicly documented, encouraging transparency and collaboration within the AI research community.
<br/>
Dolma stands out as the largest open dataset of its kind, containing 3 billion tokens of content volume. To ensure responsible use, AI2 has established the "ImpACT license for medium-risk artifacts." Prospective users must provide their contact information, disclose how they intend to use Dolma, share any creations derived from it, and agree not to apply the dataset in prohibited areas like surveillance or disinformation.
<br/>
The release of Dolma represents a departure from the norm in the competitive landscape of AI, where companies typically guard their training data and models closely. AI2's approach seeks to empower external researchers by providing a transparent and accessible resource, enabling them to understand, study, and replicate the processes behind language models.
<br/>
Dolma's availability on platforms like Hugging Face further promotes its ease of access and usability for researchers interested in developing new language models or enhancing existing ones. While Dolma isn't the first open dataset, its size and comprehensiveness set it apart, potentially fostering greater understanding and advancement in the field of natural language processing.
<br/>
<Button
  address="https://techcrunch.com/2023/08/18/ai2-drops-biggest-open-dataset-yet-for-training-language-models/"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Arthur releases open source tool to help companies find the best LLM for a job***
<br/>
<Image src="/GettyImages-1498739028.jpeg" alt="" width={700} height={650} />
<br />
Arthur, a machine learning monitoring startup, is capitalizing on the growing interest in generative AI and language model technologies. They have been developing tools to enhance companies' utilization of Large Language Models (LLMs). The company has just launched "Arthur Bench," an open-source tool designed to assist users in identifying the most suitable LLM for specific datasets.
<br/>
Adam Wenchel, CEO and co-founder of Arthur, highlights the surge in interest surrounding generative AI and LLMs. To address the challenge of effectively measuring the performance of different LLMs, Arthur created Arthur Bench. This tool allows systematic testing of LLM performance and specifically enables users to evaluate the effectiveness of prompts relevant to their application against various LLMs.
<br/>
Arthur Bench provides a suite of testing tools, and its major value lies in its ability to evaluate the performance of different LLMs against user-relevant prompts at scale. Wenchel emphasizes the potential to test numerous prompts and compare how different LLMs, such as Anthropic and OpenAI, perform on prompts aligned with user behavior. This empowers companies to make informed decisions about the best-fit LLM for their unique use case.
<br/>
The tool is being introduced as an open-source offering, with plans for a SaaS version catering to customers who prefer a managed solution or require extensive testing capabilities. Arthur recently launched Arthur Shield, an LLM firewall that detects model hallucinations, guards against harmful content, and prevents leaks of sensitive data.
<br/>
<Button
  address="https://techcrunch.com/2023/08/17/arthur-releases-open-source-tool-to-help-companies-find-the-best-llm-for-a-job/"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Generative AI datasets could face a reckoning | The AI Beat***
<br/>
The aftermath of VB Transform 2023 has been overshadowed by a revelation from The Atlantic, which unveiled that renowned authors like Stephen King, Zadie Smith, and Michael Pollan had their copyrighted works utilized to train Meta's AI model, LLaMA, alongside other large language models through the "Books3" dataset. This disclosure has sparked a contentious debate on the ethics and legality of using copyrighted materials to fuel AI advancements.
<br/>
The issue of whether this usage constitutes "stolen" content remains unsettled due to the complex landscape of copyright law. The AI community's practice of employing copyrighted materials for training, known as "fair use," is a contentious topic. The dispute may not only play out in legal battles but also in public perception.
<br/>
The utilization of copyrighted datasets for training AI models has long been an open secret, with legal experts divided on the matter. However, the implications for creators have become more pronounced as AI models like ChatGPT transition from academic experiments to profitable commercial entities. Content creators are awakening to the fact that their work has been absorbed into datasets, potentially threatening their livelihoods.
<br/>
LLM companies such as OpenAI, Anthropic, Cohere, and Meta have become less transparent about their training datasets. Authors like Sarah Silverman, Richard Kadrey, and Christopher Golden have even taken legal action, alleging copyright infringement in the training of AI models.
<br/>
The Atlantic's investigation revealed that over 170,000 books, including works by Jennifer Egan, Jonathan Franzen, and Margaret Atwood, were used in training AI models like LLaMA and BloombergGPT. Some AI companies are now focusing on creating datasets with licensed documents to address these concerns.
<br/>
This issue extends beyond copyright and data privacy; it raises questions about the impact of generative AI models on society and the workplace. A reckoning appears imminent, with potential legal battles that could reach the Supreme Court. To navigate this complex landscape, enterprises and AI companies should prioritize transparency in their data collection practices. As the AI field evolves and seeks commercial success, the tension between data acquisition and copyright protection may ultimately lead to a critical juncture.
<br/>
<Button
  address="https://venturebeat.com/ai/generative-ai-datasets-could-face-a-reckoning-the-ai-beat/"
  text="Source"
/>

