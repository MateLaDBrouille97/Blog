---
title: "Trust in Artificial Intelligence"
layout: "Article"
tags:
  -News
  -Router
  -Opinions
  -Techs
  -Trust
 
excerpt:
publishedAt:
---
<br/>
The "Trust in Artificial Intelligence" report, conducted by the University of Queensland and KPMG Australia, surveyed over 17,000 people from 17 countries and found that only half of respondents think the benefits of AI outweigh the risks. The study shows that most people are hesitant to trust AI systems and raises concerns about whether AI systems (inclusive of data, algorithms and applications) are worthy of trust. People expect AI to be regulated with some form of external, independent oversight, but view current regulations and safeguards as inadequate. The study also showed that trust in AI is contextual and depends on specific applications such as healthcare and public safety, which are more trusted than AI use in human resources.
<br/>
<Image src="/willingnesstotrust.png" alt="" width={600} height={500} />
<br/>
Cybersecurity is named as the number one concern across all countries, followed by privacy breaches, biased outcomes, and job loss. The report recommends organisations to implement assurance mechanisms to help signal ethical and responsible use of AI systems and support universal application of the Trustworthy AI principles proposed by the European Commission.
<br/>
The use of AI poses risks and challenges, and concerns about whether AI systems are trustworthy have been fuelled by high profile cases of AI use that were biased, discriminatory, manipulative, unlawful, or violated human rights. Realising the benefits of AI requires maintaining the public’s trust. People need to be confident AI is being developed and used in a responsible and trustworthy manner. Sustained acceptance and adoption of AI in society are founded on this trust.
<br/>
<Image src="/willingnesstoTrust2.png" alt="" width={600} height={500} />
<br/>
The research provides comprehensive, timely, global insights into the public’s trust and acceptance of AI systems, including who is trusted to develop, use and govern AI, the perceived benefits and risks of AI use, community expectations of the development, regulation and governance of AI, and how organisations can support trust in their AI use. It also sheds light on how people feel about the use of AI at work, current understanding and awareness of AI, and the key drivers of trust in AI systems.
<br/>
Additionally, the report found that while two-thirds of people feel optimistic about the use of AI, about half feel worried. While optimism and excitement are dominant emotions in many countries, particularly the BICS countries, fear and worry are dominant emotions for people in Australia, Canada, France, and Japan. People in France are the most fearful, worried, and outraged about AI.
<br/>
<Image src="/willingnesstoTrust3.png" alt="" width={600} height={500} />
<br/>
The report recommends organisations implementing assurance mechanisms to help signal ethical and responsible use of AI systems and support universal application of the Trustworthy AI principles to strengthen trust in AI systems. While full automation may maximise efficiency and cost reduction, it can undermine trust and acceptance. Cybersecurity is crucial in the digital age, and protecting people’s data and privacy from cybercrime is of utmost importance. Education should play a role in informing people of potential risks and benefits, as well as methods for safe and responsible use, to uplift public and consumer literacy and understanding of data and technology and help achieve a balance that enables trusted adoption.
<br/>
<Button
  address="https://assets.kpmg.com/content/dam/kpmg/au/pdf/2023/trust-in-ai-global-insights-2023.pdf?trk=public_post-text"
  text="Source"
/>