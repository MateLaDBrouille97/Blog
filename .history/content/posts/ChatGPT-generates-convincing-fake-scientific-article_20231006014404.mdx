---
title: "ChatGPT generates 'convincing' fake scientific article"
layout: "Article"
tags: 
  -Definition
  -IT
  -News
  
excerpt:
publishedAt:
---
<br/>
A recent study led by Dr. Martin Májovský and his team at Charles University, Czech Republic, has unveiled a concerning revelation about the capabilities of AI language models like ChatGPT in generating fraudulent scientific articles that closely mimic genuine research papers. The study, published in the Journal of Medical Internet Research, raises significant concerns regarding the integrity of scientific research and the reliability of published articles.
<br/>
The researchers employed ChatGPT, an AI chatbot based on OpenAI's GPT-3 language model, to fabricate a fictitious scientific article in the field of neurosurgery. They refined their questions and prompts iteratively as ChatGPT generated responses, resulting in an article that closely resembled authentic scientific papers in terms of language, structure, and content. Remarkably, the entire article creation process took just one hour without any specialized training.
<br/>
However, despite its sophistication, expert readers were able to identify semantic inaccuracies and errors, particularly in the references section. Some references were incorrect, and others did not exist. This highlights the need for improved detection methods and vigilance to combat potential AI misuse in scientific research.
<br/>
The study underscores the importance of establishing ethical guidelines and best practices for the use of AI language models in genuine scientific writing and research. While these tools can enhance efficiency and accuracy, they also pose risks of misuse. Dr. Pedro Ballester, in a commentary on the article, emphasizes the importance of prioritizing reproducibility and visibility in scientific works to prevent fraudulent research.
<br/>
As AI technology advances, it becomes imperative for the scientific community to verify the accuracy and authenticity of content generated by AI tools and implement mechanisms to detect and prevent fraud. Possible solutions include disclosing the extent of AI assistance in research and making the submission of data sets mandatory. The study title aptly labels this challenge as "Pandora's Box," highlighting the need for responsible AI use in scientific endeavors.
<br/>
<Button
  address="https://medicalxpress.com/news/2023-07-chatgpt-generates-convincing-fake-scientific.html"
  text="Source"
/>
<br/>
<br/>
<br/>
<br/>
# Others Keys Reads
<br/>
# ***ChatGPT has written its first scientific article: is it convincing?***
<br/>
In a potentially groundbreaking development, ChatGPT, an artificial intelligence conversational agent developed by OpenAI, authored a scientific article without human intervention. Researchers at the Israeli Technion Institute of Technology provided ChatGPT with a dataset from the Centers for Disease Control and Prevention, containing health and lifestyle information from 253,680 individuals, including data on fruit and vegetable consumption, physical activity, and diabetes status.
<br/>
Using this data, ChatGPT generated a program to analyze it, with human researchers correcting any errors. Eventually, ChatGPT concluded that higher consumption of fruits and vegetables and regular physical activity were associated with a reduced risk of diabetes.
<br/>
The resulting article, published online by the researchers, closely resembled a traditional research paper, except for the absence of author affiliations. However, earlier drafts contained fabricated information and false references, a known limitation of ChatGPT. The AI also struggled with proper statistical analysis and controlling for confounding factors.
<br/>
Despite these limitations, researchers believe that ChatGPT could become a valuable tool for automating repetitive tasks in research, allowing scientists to focus on more critical questions. This development underscores the growing role of artificial intelligence in scientific research. While AI's utility depends on responsible use as a research tool or a replacement for humans, it challenges the traditional boundaries of scientific authorship and the need for human supervision to ensure the validity of findings. The use of AI in scientific writing presents both opportunities and challenges, raising questions about the evolving landscape of research and publication in the future.
<br/>
<Button
  address="https://www.sciencesetavenir.fr/high-tech/intelligence-artificielle/chatgpt-a-ecrit-son-premier-article-scientifique-est-il-convaincant_172575"
  text="Source"
/>
<br/>
<br/>
<br/>
# ***Machine learning-based preeclampsia risk prediction***
<br/>
A recent study published on the medRxiv preprint server introduces an innovative machine learning-based model for estimating the risk of preeclampsia throughout pregnancy. Preeclampsia is a serious condition characterized by high blood pressure and proteinuria after the 20th week of gestation, posing significant risks to both maternal and infant health. Presently, there is no definitive cure for preeclampsia, making early detection crucial.
<br/>
The study utilized the MERLIN platform and involved a large cohort of women who gave birth in New England. Researchers collected data on sociodemographics, family history, clinical diagnoses, vital signs, and laboratory reports at multiple stages of pregnancy. Machine learning algorithms, including linear regression, xgboost random forest classifiers, deep neural networks, and elastic net models, were employed to develop the risk prediction tool.
<br/>
The results indicated that the model had a high predictive accuracy, with AUC values ranging from 0.7 to 0.9. Importantly, the machine learning tool outperformed traditional methods for identifying preeclampsia risk in the first trimester, potentially enabling the early identification of high-risk individuals.
<br/>
Furthermore, the model suggested that a larger proportion of pregnant women could benefit from aspirin prophylaxis compared to current guidelines. If aspirin prophylaxis could prevent a significant portion of preeclampsia cases, this updated risk prediction approach could potentially prevent more cases of early-onset preeclampsia.
<br/>
The study highlighted the significance of various factors in predicting preeclampsia risk, including blood pressure, laboratory reports, vital signs, and maternal age. It also noted that machine learning-based approaches offer substantial advantages over traditional methods, which often lack depth and generalizability.
<br/>
This research presents a promising machine learning model for preeclampsia risk prediction that could enhance perinatal care by identifying high-risk individuals early in pregnancy. Accurate risk assessment can lead to improved clinical treatment, surveillance, and care escalation, potentially reducing the incidence of iatrogenic preterm births. However, it's important to note that this study is preliminary and has not yet undergone peer review.
<br/>
<Button
  address="https://www.news-medical.net/news/20230821/Machine-learning-based-preeclampsia-risk-prediction.aspx"
  text="Source"
/>
<br/>
<br/>
<Button
  address="https://www.medrxiv.org/content/10.1101/2023.08.16.23293946v1"
  text="Link to PDF "
/>
<br/>
<br/>
<br/>
# ***Scientists say biocomputers made from tiny ‘brains’ are the future.***
<br/>
A group of leading scientists has proposed a groundbreaking concept known as "organoid intelligence" (OI), which envisions the fusion of biological brain cells with traditional computing to create a new form of intelligent computing. Brain organoids, three-dimensional cultures of human brain cells grown in vitro, serve as the foundation for this innovation. These miniature brain-like structures have already been used for studying brain function, disease modeling, and drug development.
<br/>
Brain organoids are created from human skin cells that are reprogrammed into stem cells, which are then guided to develop into neurons. When cultured in a gel-like matrix, these neurons form complex structures that resemble the human brain. While computers excel at raw data processing, they struggle with tasks like image recognition or complex motor coordination, where the human brain excels.
<br/>
The OI concept aims to harness the unique capabilities of biological brains, such as intuitive thinking, continuous learning, and energy-efficiency. Researchers have made significant strides in interfacing brain organoids with computer technology, opening up possibilities for enhanced computing and insights into brain function and diseases like Alzheimer's.
<br/>
Despite its potential, there are substantial challenges ahead. Currently, brain organoids contain far fewer neurons than a fully functional brain, limiting their computing power. Achieving a level of intelligence comparable to modern computers may take decades, if ever possible. Ethical considerations also play a crucial role, with scientists actively involving ethicists to ensure responsible research practices.
<br/>
The vision of organoid intelligence has the potential to revolutionize computing, healthcare, and neuroscience. While it remains a long-term goal, initiatives like the Baltimore Declaration toward OI are fostering collaboration among researchers to make this vision a reality. Tapping into the vast potential of the human brain's complexity could be transformative, but it will require careful navigation of scientific, ethical, and technological challenges along the way.
<br/>
<Button
  address="https://www.zmescience.com/science/news-science/scientists-say-biocomputers-made-from-tiny-brains-are-the-future-heres-why/"
  text="Source"
/>

