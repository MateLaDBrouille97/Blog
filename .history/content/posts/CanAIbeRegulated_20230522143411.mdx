---
title: "Can AI be regulated?"
layout: "Article"
tags: 
  -Definition
  -IT
  -News
  -Tech
  -Technologies
  -Opinion
  -AI
excerpt:
publishedAt:
---

<br/>
Traditionally, AI regulation focused on controlling the applications of the technology, especially in high-risk sectors such as healthcare. However, the emergence of all-purpose chatbots like ChatGPT presents a new question: Should the AI models themselves be regulated? This shift in focus poses unique challenges for regulators.
<br/>
The distinguishing line between benign and malevolent uses of general-purpose technologies like AI becomes blurred. Moreover, AI developers often struggle to fully explain the inner workings of their models or predict their outputs with precision. Efforts are underway to address these challenges, with the National Institute of Standards and Technology in the US spearheading the development of standards for the design, testing, and deployment of AI systems. Transparency is a key focal point, allowing external scrutiny of these models. Leading AI companies like OpenAI and Google are actively exploring ways to enhance transparency and openness to assuage concerns surrounding the formidable and enigmatic nature of AI.
<br/>
The article proposes various approaches to regulate large language models (LLMs) like ChatGPT. One option is to adopt a GPS-like positioning system, where the use of the most powerful versions is restricted. However, enforcing such limitations in a competitive market presents significant challenges. Another perspective put forth by OpenAI CEO Sam Altman suggests subjecting LLMs to direct regulatory oversight through a licensing regime, ensuring adherence to safety standards and rigorous vetting processes.
<br/>
However, implementing direct regulation for LLMs has its drawbacks. It may result in the creation of a separate market consisting of regulated models controlled by a handful of companies capable of navigating a highly regulated environment. The rapid pace of AI development further complicates the matter, as today's cutting-edge models swiftly transition into commonplace software. Additionally, smaller models specifically trained for narrower tasks may soon possess capabilities similar to large, all-purpose models like ChatGPT.
<br/>
Despite the absence of easy solutions, the increasing calls for oversight from within the technology community suggest that some form of direct regulation is inevitable. The article concludes that striking a balanced regulatory approach is imperative. This approach must consider both the potential risks associated with AI and the imperative to foster innovation in the field. It is through this delicate balance that we can navigate the uncharted waters of AI regulation, safeguarding against harm while nurturing the groundbreaking potential that AI brings to our world.
<br/>
<Button
  address="https://www.ft.com/content/8446842c-537a-4fc4-9e02-667d719526ae"
  text="Source"
/>