---
title: "Europe spins up AI research hub to apply accountability rules on Big Tech"
layout: "Article"
tags: 
  -Definition
  -IT
  -News
  -Tech
  -Technologies
  -Opinion
  -AI
  -Human Intelligence
excerpt:
publishedAt:
---
<br />
The world of tech is constantly evolving, and so too are the concerns surrounding it. One such concern is the lack of transparency in algorithms used by large digital platforms such as Facebook, Instagram, and TikTok. The European Centre for Algorithmic Transparency (ECAT) has been launched in Seville to address this very issue.
<br />
The EU's Digital Services Act (DSA) aims to set new standards in online safety by using mandatory transparency to force tech giants to open up about the workings of their algorithms. This means that under the DSA, special oversight regimes will designate "very large online platforms" (VLOPs) and "very large online search engines" (VLOSE) to proactively assess systemic risks posed by their algorithms and apply mitigations.
<br />
But how will this be achieved? That's where the ECAT comes in. The centre is tasked with identifying "smoking guns" to drive DSA enforcement, providing evidence for the Commission to build cases for breaches of the digital rulebook. This means that the ECAT will be the jewel in the crown of the Commission's DSA toolbox, staffed by a team of experts bringing scientific rigor, expertise, and human feeling to the task of auditing the immediate impacts of AI effects.
<br />
The ECAT's role is essential, as algorithms are often used to make decisions that have a significant impact on our lives, from determining what content we see on social media to influencing our purchasing decisions. This lack of transparency can lead to a lack of accountability, and in some cases, discrimination.
<br />
The ECAT will play a major role in interrogating the algorithms of large digital platforms and providing transparency to the public. This will not only promote accountability and safety online, but also encourage tech giants to consider the ethical implications of their algorithms.
<br />
In addition to identifying smoking guns, the ECAT will also be tasked with limiting profiling-driven content feeds and the use of personal data for targeted advertising. This will ensure that individuals' privacy is protected and that their personal information is not used without their knowledge or consent.
<br />
<Button
  address="https://techcrunch.com/2023/04/18/ecat/"
  text="Source"
/>
